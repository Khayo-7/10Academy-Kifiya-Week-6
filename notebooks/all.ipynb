{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from scripts.data_utils.cleaner import *\n",
    "from scripts.modeling.process import process_data\n",
    "from scripts.data_utils.preprocess import preprocess_data\n",
    "from scripts.data_utils.loaders import load_data, save_data\n",
    "from scripts.modeling.orchestrator import *\n",
    "from scripts.modeling.model import prepare_for_modeling, CreditScoringModel\n",
    "\n",
    "# import matplotlib\n",
    "# matplotlib.use('TkAgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCEPATH = os.path.join('..', 'resources')\n",
    "DATAPATH = os.path.join(RESOURCEPATH, 'data')\n",
    "raw_data_path = os.path.join(DATAPATH, 'raw')\n",
    "\n",
    "prepreocessed_output_dir = os.path.join(DATAPATH, 'preprocessed')\n",
    "processed_output_dir = os.path.join(DATAPATH, 'processed')\n",
    "plot_output_dir = os.path.join('..', 'screenshots', 'plots')\n",
    "\n",
    "os.makedirs(prepreocessed_output_dir, exist_ok=True)\n",
    "os.makedirs(processed_output_dir, exist_ok=True)\n",
    "os.makedirs(plot_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data.csv'\n",
    "file_path = os.path.join(raw_data_path, filename)\n",
    "data_csv = load_data(file_path)\n",
    "data_csv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = 'data.xlsx'\n",
    "file_path2 = os.path.join(raw_data_path, filename2)\n",
    "data_xlsx = load_data(file_path2, sheet_name='data')\n",
    "data_xlsx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_xlsx.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant_columns = ['Unnamed: 16', 'Unnamed: 17']\n",
    "numerical_columns = ['Amount', 'Value', 'PricingStrategy']\n",
    "categorical_columns = [\"CurrencyCode\", \"CountryCode\", \"ProviderId\", \"ProductId\", \"ProductCategory\", \"ChannelId\"]\n",
    "date_column = \"TransactionStartTime\"\n",
    "\n",
    "missing_value_strategies = {\n",
    "        \"CountryCode\": \"most_frequent\",\n",
    "        \"AccountId\": \"most_frequent\",\n",
    "        \"ProviderId\": \"most_frequent\",\n",
    "        \"PricingStrategy\": \"median\",\n",
    "        \"Value\": \"mean\",\n",
    "}\n",
    "dtype_conversions = {\n",
    "        \"CountryCode\": \"int64\",\n",
    "        \"CountryCode\": \"str\",\n",
    "}\n",
    "\n",
    "data = data_xlsx.copy()\n",
    "\n",
    "data_preprocessed = preprocess_data(data, irrelevant_columns, categorical_columns, numerical_columns, \n",
    "                                    missing_value_strategies, date_column, dtype_conversions, processed_output_dir)\n",
    "data_preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target feature and feature lists\n",
    "numerical_columns = ['Amount', 'Value', 'PricingStrategy']\n",
    "rfms_features = ['Recency', 'Frequency', 'Monetary', 'Intensity', 'Volatility', 'Severity']\n",
    "temporal_features = ['transaction_hour', 'transaction_day', 'transaction_month', 'transaction_year']\n",
    "drop_columns = ['TransactionStartTime', 'TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId']\n",
    "categorical_columns = ['CurrencyCode', 'CountryCode', 'ProviderId', 'ProductId', 'ProductCategory', 'ChannelId']\n",
    "aggregated_features = ['total_transaction_amount', 'avg_transaction_amount', 'std_transaction_amount']#, 'transaction_count']\n",
    "\n",
    "numerical_features = numerical_columns + aggregated_features\n",
    "columns = categorical_columns + numerical_features\n",
    "woe_columns = columns + aggregated_features + rfms_features\n",
    "\n",
    "score_column = rfms_features[2]\n",
    "cluster_column = rfms_features[0]\n",
    "# cluster_column = 'Cluster'\n",
    "date_column = 'TransactionStartTime'\n",
    "target_column = 'FraudResult'\n",
    "customer_column = \"CustomerId\"\n",
    "customer_label = \"RFMS_Label\"\n",
    "recency_column = date_column\n",
    "frequency_column = 'TransactionId'\n",
    "amount_column = 'Amount'\n",
    "monetary_column = 'Value'\n",
    "severity_column = target_column\n",
    "timezone = 'Africa/Addis_Ababa'\n",
    "max_bins = 5\n",
    "\n",
    "data = data_preprocessed.copy()\n",
    "scaler= None\n",
    "data_processed = process_data(data, numerical_features, date_column, customer_column, recency_column, frequency_column, monetary_column, \n",
    "             severity_column, target_column, customer_label, columns, rfms_features, scaler, processed_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run the model pipeline\n",
    "data_final = prepare_for_modeling(data_processed, customer_label, drop_columns)\n",
    "X = data_final.drop(columns=[target_column])\n",
    "y = data_final[target_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_model = CreditScoringModel()\n",
    "best_model = credit_model.train(X_train, y_train, X_test, y_test)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "metrics = credit_model.evaluate_model(best_model, X_test, y_test)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.modeling.transformers import *\n",
    "from scripts.data_utils.data_transformers import *\n",
    "\n",
    "transformation_pipeline = get_transformation_pipeline(\n",
    "    irrelevant_columns, missing_value_strategies, date_column, categorical_columns, numerical_columns,\n",
    "    dtype_conversions, timezone, customer_column, amount_column, numerical_features,\n",
    "    recency_column, frequency_column, monetary_column, severity_column, rfms_features,\n",
    "    target_column, max_bins, score_column, customer_label\n",
    ")\n",
    "transformation_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_xlsx.copy()\n",
    "data_processed_tr = transformation_pipeline.fit_transform(data)\n",
    "data_processed_tr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed_tr.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_pipeline = get_modeling_pipeline(drop_columns, customer_label)\n",
    "modeling_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_transformed = transformation_pipeline.fit_transform(data)\n",
    "data_transformed = data_processed_tr.copy()\n",
    "\n",
    "# data_final = prepare_for_modeling(data_processed_trf, customer_label, drop_columns)\n",
    "X = data_transformed.drop(columns=[target_column])\n",
    "y = data_transformed[target_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# model = CreditScoringModel()\n",
    "# best_model = model.train(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = FullPipelineModel(transformation_pipeline, modeling_pipeline)\n",
    "full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the full pipeline\n",
    "full_pipeline.save('full_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full pipeline for inference\n",
    "loaded_pipeline = FullPipelineModel.load('full_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on new data\n",
    "# predictions = loaded_pipeline.predict(new_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
